# gpt-k: Next-token prediction to Multi-token prediction

The project undertaken by the authors aims to explore methods for speeding up LLM inference through prediction of multiple tokens in a single pass. Currently, 2 methods are being explored:

1.Matrix Based:

2. LSTM Based: K-steps forward pass is achieved through an LSTM model. 
