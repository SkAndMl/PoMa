llama_path = "/Users/sathyakrishnansuresh/.llama/checkpoints/Llama3.2-1B"

# TODO: all these params are randomly set. should be tuned
max_seq_len = 512
max_batch_size = 64
epochs = 3
lr = 3e-4
wd = 1e-2
